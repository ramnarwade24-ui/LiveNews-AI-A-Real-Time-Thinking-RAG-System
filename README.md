LiveNewsAI â€” Real-Time Streaming RAG System for Breaking News

ğŸš€ Production-grade real-time Retrieval Augmented Generation (RAG) system built with Pathway that continuously ingests breaking news and answers questions using the latest articles â€” without requiring restarts or re-indexing.

Live AI â€” Answers update automatically as new articles arrive. No batch processing. No manual re-indexing.

ğŸ¥ Hackathon Live Demo

Live Swagger UI (GitHub Codespaces):
https://curly-umbrella-4j5x7vp6pxvqcjrj-8000.app.github.dev/docs

Health Check:
https://curly-umbrella-4j5x7vp6pxvqcjrj-8000.app.github.dev/health

Example Query:

"What are today's top business headlines?"

The system demonstrates:

Real-time ingestion

Streaming vector indexing

Live retrieval

RAG pipeline execution


âš™ï¸ How To Run (Step-by-Step)

This project can run locally or using Docker.

ğŸ”¹ Option 1: Run Locally (Recommended for Judges)
Prerequisites

Python 3.10+

NewsAPI key (free from https://newsapi.org
)

OpenAI API key (optional, only for AI summaries)

Step 1 â€” Clone Repository
git clone https://github.com/ramnarwade24-ui/LiveNews-AI-A-Real-Time-Thinking-RAG-System
cd LiveNews-AI-A-Real-Time-Thinking-RAG-System

Step 2 â€” Create Virtual Environment
python -m venv venv
source venv/bin/activate   # Linux/Mac
# OR
venv\Scripts\activate      # Windows

Step 3 â€” Install Dependencies
cd livenewsai
pip install -r requirements.txt

Step 4 â€” Set Environment Variables
export NEWS_API_KEY="your-newsapi-key"

# Optional (for AI summaries)
export OPENAI_API_KEY="your-openai-key"

Step 5 â€” Start Server
python app.py


Server will start at:

http://localhost:8000


Swagger UI:

http://localhost:8000/docs

ğŸ”¹ Option 2: Run Using Docker
Prerequisites

Docker

Docker Compose

Step 1 â€” Set API Keys
export NEWS_API_KEY="your-newsapi-key"
export OPENAI_API_KEY="your-openai-key"   # optional

Step 2 â€” Run
docker-compose up --build


Server will start at:

http://localhost:8000

ğŸ” How To Verify It Is Working
1ï¸âƒ£ Health Check
curl http://localhost:8000/health


Expected Output:

{
  "status": "healthy",
  "pipeline_running": true,
  "index_size": 50,
  "timestamp": "2026-01-18T14:05:22.470465"
}

2ï¸âƒ£ Ask Question
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What are today's top business headlines?",
    "top_k": 5
  }'

3ï¸âƒ£ Real-Time Streaming Proof

Check index growth:

curl http://localhost:8000/stats


You will see index size increasing every minute as new news arrives.

ğŸ§  Graceful AI Fallback Mode (No OpenAI Credits Required)

If OpenAI quota is unavailable, system automatically switches to fallback mode:

{
  "answer": "AI model temporarily unavailable â€” showing retrieved news context.",
  "article_summaries": [...],
  "sources": [...],
  "ai_status": "rate_limited"
}


âœ” Real-time retrieval still works
âœ” Indexing still runs
âœ” Streaming pipeline stays active
âœ¨ Key Features

Real-Time Streaming â€” Continuously ingests news from NewsAPI every 60 seconds

Dynamic Vector Index â€” Live KNN index updates automatically

RAG-Powered Answers â€” Questions answered using latest articles

Zero Downtime Updates â€” New articles indexed without restart

FastAPI REST API â€” Production-ready API with Swagger UI

Docker-Ready â€” One-command deployment

Fully Async â€” High concurrency support

Modular Architecture â€” Clean extensible codebase

â­ Bonus Capabilities

Graceful AI Fallback â€” If OpenAI quota is unavailable, system still returns real-time retrieved news context, article summaries, and sources.

No-Credit Mode â€” Fully functional retrieval + indexing pipeline without OpenAI credits.

ğŸ—ï¸ Architecture
Live News Stream (NewsAPI)
        â†“
   Pathway Connector
        â†“
  Streaming Pipeline
        â†“
  Embeddings (OpenAI)
        â†“
  Real-Time Vector Index (KNN)
        â†“
   RAG Query Engine
        â†“
  LLM Answer Generation (GPT-4o-mini with fallback mode)
        â†“
   FastAPI REST API

ğŸš€ Quick Start
Prerequisites

Python 3.10+ or Docker

NewsAPI key (free at https://newsapi.org
)

OpenAI API key (optional, only for AI summaries)

Local Setup
git clone https://github.com/ramnarwade24-ui/LiveNews-AI-A-Real-Time-Thinking-RAG-System
cd LiveNews-AI-A-Real-Time-Thinking-RAG-System

export NEWS_API_KEY="your-newsapi-key"

# Optional: only required for AI-generated answers
export OPENAI_API_KEY="your-openai-key"

bash quickstart.sh


Server runs at:
ğŸ‘‰ http://localhost:8000

ğŸ‘‰ Swagger UI: http://localhost:8000/docs

Docker Setup
export NEWS_API_KEY="your-newsapi-key"
export OPENAI_API_KEY="your-openai-key"   # optional

bash docker-quickstart.sh

ğŸ“– API Examples
Ask a Question
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What are the latest AI breakthroughs?",
    "top_k": 5
  }'

Health Check
curl http://localhost:8000/health

Get Stats
curl http://localhost:8000/stats

ğŸ§  Graceful Fallback Mode (No OpenAI Credits Required)

If OpenAI quota is unavailable, the system automatically switches to fallback mode:

{
  "answer": "AI model temporarily unavailable â€” showing retrieved news context.",
  "article_summaries": [...],
  "sources": [...],
  "ai_status": "rate_limited"
}


This allows full real-time RAG functionality without paid APIs.

ğŸ“ Project Structure

LiveNews-AI-A-Real-Time-Thinking-RAG-System/
â”‚
â”œâ”€â”€ livenewsai/ # Main application package
â”‚ â”œâ”€â”€ app.py # FastAPI server
â”‚ â”œâ”€â”€ pathway_pipeline.py # Pathway streaming pipeline
â”‚ â”œâ”€â”€ connectors.py # NewsAPI connector
â”‚ â”œâ”€â”€ rag.py # RAG query engine
â”‚ â”œâ”€â”€ config.py # Configuration
â”‚ â”œâ”€â”€ requirements.txt # Dependencies
â”‚ â””â”€â”€ test_livenewsai.py # Tests
â”‚
â”œâ”€â”€ Dockerfile # Docker image
â”œâ”€â”€ docker-compose.yml # Multi-container setup
â”œâ”€â”€ quickstart.sh # Local quick start
â”œâ”€â”€ docker-quickstart.sh # Docker quick start
â”œâ”€â”€ DEPLOYMENT.md # Deployment guide
â”œâ”€â”€ .env.example # Environment template
â””â”€â”€ README.md # Project documentation

ğŸ”§ Configuration
export NEWS_POLLING_INTERVAL=60
export NEWS_BATCH_SIZE=20
export EMBEDDING_MODEL=text-embedding-3-small
export TOP_K_RESULTS=5
export LLM_MODEL=gpt-4o-mini
export LOG_LEVEL=INFO

ğŸ› ï¸ Tech Stack
Component	Technology
Streaming	Pathway
Framework	FastAPI
Embeddings	OpenAI
LLM	GPT-4o-mini
Data	NewsAPI
Vector Index	In-Memory KNN
Server	Uvicorn
Container	Docker
ğŸš¦ API Endpoints
Method	Endpoint	Purpose
GET	/	API info
GET	/health	System status
POST	/ask	Ask question
GET	/stats	System statistics
GET	/articles	Recent articles
GET	/docs	Swagger UI
ğŸ“Š Performance

Latency: <500ms

Streaming updates every 60 seconds

Index grows live without restart

Supports concurrent users

ğŸ§ª Testing
pytest livenewsai/test_livenewsai.py -v

ğŸ“ˆ Monitoring
curl http://localhost:8000/health
curl http://localhost:8000/stats

ğŸ“œ License

MIT License

ğŸ Hackathon Readiness

âœ” Real-time streaming
âœ” Pathway pipeline
âœ” RAG architecture
âœ” Live demo
âœ” Public GitHub repo
âœ” API documentation
âœ” Docker deployment
âœ” Graceful failure handling

ğŸ’¡ Use Cases

Real-time news assistant

Market intelligence

AI-powered newsroom

Research monitoring

Breaking news summarizer

ğŸ¤ Team

Built for DataQuest 2026 â€“ Team Megalith (IIT Kharagpur)
Hackathon Category: Real-Time Data Science & AI Systems

Made with â¤ï¸ using Pathway, FastAPI, and OpenAI

Live Demo â€¢ Real-Time Streaming â€¢ Production Ready
